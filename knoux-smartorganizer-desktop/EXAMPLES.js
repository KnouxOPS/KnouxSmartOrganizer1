/**
 * ğŸ§  Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
 * Knoux SmartOrganizer PRO - Live Examples
 */

const { pipeline, RawImage } = require("@xenova/transformers");
const nsfw = require("nsfwjs");
const faceapi = require("@vladmandic/face-api");
const { createWorker } = require("tesseract.js");
const { phash } = require("image-hash");
const sharp = require("sharp");
const fs = require("fs");

// ==========================================
// 1. ğŸ¯ Ù…Ø«Ø§Ù„: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLIP
// ==========================================

async function exampleImageClassification() {
  console.log("ğŸ¯ Ù…Ø«Ø§Ù„: ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆï¿½ï¿½ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLIP");

  // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
  const classifier = await pipeline(
    "zero-shot-image-classification",
    "Xenova/clip-vit-base-patch32",
  );

  // ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
  const imageBuffer = fs.readFileSync("example-image.jpg");
  const { data, info } = await sharp(imageBuffer).raw().toBuffer({
    resolveWithObject: true,
  });
  const rawImage = new RawImage(data, info.width, info.height, info.channels);

  // Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
  const candidateLabels = [
    "person",
    "selfie",
    "nature",
    "landscape",
    "food",
    "animal",
    "car",
    "building",
    "document",
    "screenshot",
  ];

  // Ø§Ù„ØªØµÙ†ÙŠÙ
  const result = await classifier(rawImage, candidateLabels);

  console.log("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ:");
  result.forEach((r, index) => {
    console.log(`  ${index + 1}. ${r.label}: ${(r.score * 100).toFixed(1)}%`);
  });

  return {
    classification: result[0].label,
    confidence: result[0].score,
    allResults: result,
  };
}

// ==========================================
// 2. ğŸ“ Ù…Ø«Ø§Ù„: ÙˆØµÙ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Vision-GPT
// ==========================================

async function exampleImageCaptioning() {
  console.log("ğŸ“ Ù…Ø«Ø§Ù„: ÙˆØµÙ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³Øªï¿½ï¿½Ø¯Ø§Ù… Vision-GPT");

  // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
  const imageToTextGenerator = await pipeline(
    "image-to-text",
    "Xenova/vit-gpt2-image-captioning",
  );

  // ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
  const imageBuffer = fs.readFileSync("example-image.jpg");
  const { data, info } = await sharp(imageBuffer).raw().toBuffer({
    resolveWithObject: true,
  });
  const rawImage = new RawImage(data, info.width, info.height, info.channels);

  // ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ
  const captionResult = await imageToTextGenerator(rawImage);
  const description = captionResult[0].generated_text;

  console.log("ğŸ“ Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…ÙˆÙ„Ø¯:", description);

  // Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ù…Ù„Ù Ø°ÙƒÙŠ
  const timestamp = new Date().toISOString().slice(0, 10);
  const safeDescription = description
    .replace(/[^a-zA-Z0-9\s]/g, "")
    .replace(/\s+/g, "-")
    .slice(0, 30);

  const smartFilename = `${timestamp}-${safeDescription}.jpg`;
  console.log("ğŸ“ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙƒÙŠ:", smartFilename);

  return {
    description,
    smartFilename,
  };
}

// ==========================================
// 3. ğŸš« Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø³Ø§Ø³
// ==========================================

async function exampleNSFWDetection() {
  console.log("ğŸš« Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø³Ø§Ø³");

  // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
  const nsfwModel = await nsfw.load();
  const tf = require("@tensorflow/tfjs-node");

  // ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
  const imageBuffer = fs.readFileSync("example-image.jpg");
  const tensor = tf.node.decodeImage(imageBuffer, 3);

  // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
  const predictions = await nsfwModel.classify(tensor);
  tensor.dispose(); // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©

  console.log("ğŸš« Ù†ØªØ§Ø¦Ø¬ ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰:");
  predictions.forEach((p) => {
    console.log(`  ${p.className}: ${(p.probability * 100).toFixed(1)}%`);
  });

  // ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø§Ø³
  const nsfwClasses = ["Porn", "Hentai"];
  const maxNsfwScore = Math.max(
    ...predictions
      .filter((p) => nsfwClasses.includes(p.className))
      .map((p) => p.probability),
  );

  const isNSFW = maxNsfwScore > 0.6;
  console.log(`ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: ${isNSFW ? "Ù…Ø±ÙÙˆØ¶" : "Ù…Ù‚Ø¨ÙˆÙ„"}`);

  return {
    isNSFW,
    score: maxNsfwScore,
    allPredictions: predictions,
  };
}

// ==========================================
// 4. ğŸ‘¥ Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØ§Ù„Ø¹Ù…Ø± ÙˆØ§Ù„Ø¬Ù†Ø³
// ==========================================

async function exampleFaceDetection() {
  console.log("ğŸ‘¥ Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØ§Ù„Ø¹Ù…Ø± ÙˆØ§Ù„Ø¬Ù†Ø³");

  // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
  const modelPath = "./node_modules/@vladmandic/face-api/model";
  await faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath);
  await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath);
  await faceapi.nets.ageGenderNet.loadFromDisk(modelPath);

  // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¨ÙŠØ¦Ø©
  const tf = require("@tensorflow/tfjs-node");
  const { Canvas, Image, ImageData } = require("canvas");
  faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

  // ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
  const imageBuffer = fs.readFileSync("example-image.jpg");
  const tensor = tf.node.decodeImage(imageBuffer);

  // ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡
  const detections = await faceapi
    .detectAllFaces(tensor)
    .withFaceLandmarks()
    .withAgeAndGender();

  tensor.dispose();

  console.log(`ğŸ‘¥ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ${detections.length} ÙˆØ¬Ù‡:`);

  const faces = detections.map((detection, index) => {
    const face = {
      index: index + 1,
      confidence: Math.round(detection.detection.score * 100),
      age: Math.round(detection.age),
      gender: detection.gender,
      genderConfidence: Math.round(detection.genderProbability * 100),
      box: detection.detection.box,
    };

    console.log(`  Ø§Ù„ÙˆØ¬Ù‡ ${face.index}:`);
    console.log(`    Ø§Ù„Ø«Ù‚Ø©: ${face.confidence}%`);
    console.log(`    ï¿½ï¿½Ù„Ø¹Ù…Ø±: ${face.age} Ø³Ù†Ø©`);
    console.log(`    Ø§Ù„Ø¬Ù†Ø³: ${face.gender} (${face.genderConfidence}%)`);
    console.log(
      `    Ø§Ù„Ù…ÙˆÙ‚Ø¹: x=${Math.round(face.box.x)}, y=${Math.round(face.box.y)}`,
    );

    return face;
  });

  return {
    faceCount: detections.length,
    faces,
  };
}

// ==========================================
// 5. ğŸ“– Ù…Ø«Ø§Ù„: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ (OCR)
// ==========================================

async function exampleOCR() {
  console.log("ğŸ“– Ù…Ø«Ø§Ù„: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ (OCR)");

  // ØªÙ‡ÙŠØ¦Ø© OCR
  const worker = await createWorker();
  await worker.loadLanguage("eng+ara"); // Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ + Ø¹Ø±Ø¨ÙŠ
  await worker.initialize("eng+ara");

  // Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
  const imageBuffer = fs.readFileSync("example-document.jpg");
  const {
    data: { text, confidence },
  } = await worker.recognize(imageBuffer);

  await worker.terminate();

  console.log("ğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:");
  console.log(text);
  console.log(`ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: ${Math.round(confidence)}%`);

  // ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙˆØ«ÙŠÙ‚Ø©
  const isDocument = text.trim().length > 50;
  const hasArabic = /[\u0600-\u06FF]/.test(text);
  const hasEnglish = /[a-zA-Z]/.test(text);

  console.log(`ğŸ“„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: ${isDocument ? "ÙˆØ«ÙŠÙ‚Ø©" : "Ù†Øµ Ù‚ØµÙŠØ±"}`);
  console.log(
    `ğŸŒ Ø§Ù„Ù„ØºØ§Øª: ${hasArabic ? "Ø¹Ø±Ø¨ÙŠ " : ""}${hasEnglish ? "Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ" : ""}`,
  );

  return {
    text: text.trim(),
    confidence,
    isDocument,
    hasArabic,
    hasEnglish,
    wordCount: text.trim().split(/\s+/).length,
  };
}

// ==========================================
// 6. ğŸ”„ Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
// ==========================================

async function exampleDuplicateDetection() {
  console.log("ğŸ”„ Ù…Ø«Ø§Ù„: ÙƒØ´Ù Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©");

  // Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµÙˆØ± Ù„Ù„ÙØ­Øµ
  const imageFiles = [
    "image1.jpg",
    "image2.jpg",
    "image1_copy.jpg", // Ù†Ø³Ø®Ø© Ù…Ø·Ø§Ø¨Ù‚Ø©
    "image3.jpg",
  ];

  const imageHashes = new Map();
  const duplicates = [];

  for (const file of imageFiles) {
    // Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠØ©
    const hash = await new Promise((resolve, reject) => {
      phash(file, (err, hash) => {
        if (err) reject(err);
        else resolve(hash);
      });
    });

    console.log(`ğŸ“ ${file}: ${hash}`);

    // ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø±
    if (imageHashes.has(hash)) {
      const originalFile = imageHashes.get(hash);
      duplicates.push({
        original: originalFile,
        duplicate: file,
        hash,
      });
      console.log(`ğŸ”„ ØªÙƒØ±Ø§Ø± Ù…ÙƒØªØ´Ù: ${file} Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù€ ${originalFile}`);
    } else {
      imageHashes.set(hash, file);
    }
  }

  console.log(`ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø©: ${duplicates.length} ØµÙˆØ±Ø© Ù…ÙƒØ±Ø±Ø©`);

  return {
    totalImages: imageFiles.length,
    uniqueImages: imageHashes.size,
    duplicates,
  };
}

// ==========================================
// 7. ğŸ¯ Ù…Ø«Ø§Ù„ Ø´Ø§Ù…Ù„: ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„
// ==========================================

async function exampleCompleteAnalysis() {
  console.log("ğŸ¯ Ù…Ø«Ø§Ù„ Ø´Ø§Ù…Ù„: ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„");
  console.log("=" * 50);

  try {
    // 1. ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±Ø©
    console.log("\n1ï¸âƒ£ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±Ø©...");
    const classificationResult = await exampleImageClassification();
    console.log(`âœ… Ø§Ù„ØªØµÙ†ÙŠÙ: ${classificationResult.classification}`);

    // 2. ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©
    console.log("\n2ï¸âƒ£ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©...");
    const captionResult = await exampleImageCaptioning();
    console.log(`âœ… Ø§Ù„ÙˆØµÙ: ${captionResult.description}`);

    // 3. ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø³Ø§Ø³
    console.log("\n3ï¸âƒ£ ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰...");
    const nsfwResult = await exampleNSFWDetection();
    console.log(`âœ… Ø§Ù„Ø­Ø§Ù„ï¿½ï¿½: ${nsfwResult.isNSFW ? "Ù…Ø±ÙÙˆØ¶" : "Ù…Ù‚Ø¨ÙˆÙ„"}`);

    // 4. ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡
    console.log("\n4ï¸âƒ£ ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡...");
    const faceResult = await exampleFaceDetection();
    console.log(`âœ… Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ¬ÙˆÙ‡: ${faceResult.faceCount}`);

    // 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ
    console.log("\n5ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ...");
    const ocrResult = await exampleOCR();
    console.log(`âœ… Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ: ${ocrResult.wordCount} ÙƒÙ„Ù…Ø©`);

    // 6. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    console.log("\n6ï¸âƒ£ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯...");
    let targetFolder = "others";

    if (nsfwResult.isNSFW) {
      targetFolder = "rejected";
    } else if (
      faceResult.faceCount > 0 &&
      classificationResult.classification.includes("person")
    ) {
      targetFolder = "selfies";
    } else if (ocrResult.isDocument) {
      targetFolder = "documents";
    } else if (
      ["nature", "landscape"].some((term) =>
        classificationResult.classification.includes(term),
      )
    ) {
      targetFolder = "nature";
    } else if (
      ["food", "meal"].some((term) =>
        classificationResult.classification.includes(term),
      )
    ) {
      targetFolder = "food";
    } else if (classificationResult.classification.includes("animal")) {
      targetFolder = "animals";
    }

    console.log(`âœ… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚ØªØ±Ø­: ${targetFolder}`);

    // Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    const finalResult = {
      classification: classificationResult.classification,
      confidence: classificationResult.confidence,
      description: captionResult.description,
      suggestedFilename: captionResult.smartFilename,
      isNSFW: nsfwResult.isNSFW,
      faceCount: faceResult.faceCount,
      faces: faceResult.faces,
      hasText: ocrResult.isDocument,
      extractedText: ocrResult.text.slice(0, 100) + "...",
      targetFolder,
      processingComplete: true,
    };

    console.log("\nğŸ‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…ÙƒØªÙ…Ù„!");
    console.log("ğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:");
    console.log(JSON.stringify(finalResult, null, 2));

    return finalResult;
  } catch (error) {
    console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„:", error.message);
    return { error: error.message };
  }
}

// ==========================================
// 8. ğŸš€ ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø©
// ==========================================

async function runAllExamples() {
  console.log("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø©...");
  console.log("=" * 60);

  try {
    // ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
    await exampleCompleteAnalysis();

    // ØªØ´ØºÙŠÙ„ Ù…Ø«Ø§Ù„ ÙƒØ´Ù Ø§Ù„ØªÙƒØ±Ø§Ø±
    console.log("\n" + "=" * 60);
    await exampleDuplicateDetection();

    console.log("\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­!");
  } catch (error) {
    console.error("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø«Ù„Ø©:", error);
  }
}

// ØªØµØ¯ÙŠØ± Ø§Ù„Ø¯ÙˆØ§Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
module.exports = {
  exampleImageClassification,
  exampleImageCaptioning,
  exampleNSFWDetection,
  exampleFaceDetection,
  exampleOCR,
  exampleDuplicateDetection,
  exampleCompleteAnalysis,
  runAllExamples,
};

// ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©
if (require.main === module) {
  runAllExamples();
}
