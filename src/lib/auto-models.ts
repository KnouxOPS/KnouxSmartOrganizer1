import * as tf from "@tensorflow/tfjs";
import * as faceapi from "face-api.js";

export class AutoModelManager {
  private static instance: AutoModelManager;
  private modelsLoaded = false;
  private loadingPromise: Promise<void> | null = null;

  static getInstance(): AutoModelManager {
    if (!this.instance) {
      this.instance = new AutoModelManager();
    }
    return this.instance;
  }

  async ensureModelsLoaded(): Promise<void> {
    if (this.modelsLoaded) return;
    if (this.loadingPromise) return this.loadingPromise;

    this.loadingPromise = this.loadAllModels();
    await this.loadingPromise;
  }

  private async loadAllModels(): Promise<void> {
    console.log("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹...");

    try {
      // Initialize TensorFlow
      await tf.ready();

      // Load models in parallel
      await Promise.allSettled([
        this.loadFaceModels(),
        this.loadClassificationModel(),
        this.loadOCRModel(),
      ]);

      this.modelsLoaded = true;
      console.log("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!");
    } catch (error) {
      console.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:", error);
      // Continue with fallback models
      this.modelsLoaded = true;
    }
  }

  private async loadFaceModels(): Promise<void> {
    try {
      // Load from CDN
      const MODEL_URL =
        "https://cdn.jsdelivr.net/npm/@vladmandic/face-api@latest/model";

      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
      ]);

      console.log("âœ… Face detection models loaded");
    } catch (error) {
      console.warn("âš ï¸ Face models failed, using fallback");
    }
  }

  private async loadClassificationModel(): Promise<void> {
    try {
      // Load lightweight MobileNet
      const model = await tf.loadLayersModel(
        "https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json",
      );

      // Store model globally
      (window as any).classificationModel = model;
      console.log("âœ… Classification model loaded");
    } catch (error) {
      console.warn("âš ï¸ Classification model failed, using fallback");
    }
  }

  private async loadOCRModel(): Promise<void> {
    try {
      // Tesseract loads automatically when first used
      console.log("âœ… OCR ready (Tesseract.js)");
    } catch (error) {
      console.warn("âš ï¸ OCR initialization failed");
    }
  }

  isLoaded(): boolean {
    return this.modelsLoaded;
  }

  async classifyImage(imageElement: HTMLImageElement): Promise<string> {
    await this.ensureModelsLoaded();

    try {
      const model = (window as any).classificationModel;
      if (model) {
        // Use actual model
        const canvas = document.createElement("canvas");
        canvas.width = 224;
        canvas.height = 224;
        const ctx = canvas.getContext("2d")!;
        ctx.drawImage(imageElement, 0, 0, 224, 224);

        const tensor = tf.browser
          .fromPixels(canvas)
          .expandDims(0)
          .cast("float32")
          .div(255);

        const predictions = (await model.predict(tensor)) as tf.Tensor;
        const scores = await predictions.data();

        // Simple classification based on scores
        const maxIndex = scores.indexOf(Math.max(...Array.from(scores)));
        const categories = ["Ø¹Ø§Ù…", "Ø·Ø¨ÙŠØ¹Ø©", "Ø·Ø¹Ø§Ù…", "Ù…Ø±ÙƒØ¨Ø§Øª", "Ø­ÙŠÙˆØ§Ù†Ø§Øª"];

        tensor.dispose();
        predictions.dispose();

        return categories[maxIndex % categories.length] || "Ø¹Ø§Ù…";
      }
    } catch (error) {
      console.warn("Classification failed, using fallback");
    }

    // Fallback classification
    return this.simpleColorBasedClassification(imageElement);
  }

  private simpleColorBasedClassification(img: HTMLImageElement): string {
    const canvas = document.createElement("canvas");
    canvas.width = 100;
    canvas.height = 100;
    const ctx = canvas.getContext("2d")!;
    ctx.drawImage(img, 0, 0, 100, 100);

    const imageData = ctx.getImageData(0, 0, 100, 100);
    const pixels = imageData.data;

    let totalR = 0,
      totalG = 0,
      totalB = 0;
    for (let i = 0; i < pixels.length; i += 4) {
      totalR += pixels[i];
      totalG += pixels[i + 1];
      totalB += pixels[i + 2];
    }

    const pixelCount = pixels.length / 4;
    const avgR = totalR / pixelCount;
    const avgG = totalG / pixelCount;
    const avgB = totalB / pixelCount;

    // Simple heuristics
    if (avgG > avgR && avgG > avgB && avgG > 100) return "Ø·Ø¨ÙŠï¿½ï¿½Ø©";
    if (avgR > 150 && avgG > 100 && avgB < 100) return "Ø·Ø¹Ø§Ù…";
    if (avgB > avgR && avgB > avgG) return "Ù„Ù‚Ø·Ø§Øª_Ø´Ø§Ø´Ø©";

    return "Ø¹Ø§Ù…";
  }

  async detectFaces(imageElement: HTMLImageElement): Promise<number> {
    await this.ensureModelsLoaded();

    try {
      const detections = await faceapi.detectAllFaces(
        imageElement,
        new faceapi.TinyFaceDetectorOptions(),
      );
      return detections.length;
    } catch (error) {
      // Fallback: simple skin color detection
      return this.simpleFaceDetection(imageElement);
    }
  }

  private simpleFaceDetection(img: HTMLImageElement): number {
    const canvas = document.createElement("canvas");
    canvas.width = 100;
    canvas.height = 100;
    const ctx = canvas.getContext("2d")!;
    ctx.drawImage(img, 0, 0, 100, 100);

    const imageData = ctx.getImageData(0, 0, 100, 100);
    const pixels = imageData.data;

    let skinPixels = 0;
    for (let i = 0; i < pixels.length; i += 4) {
      const r = pixels[i];
      const g = pixels[i + 1];
      const b = pixels[i + 2];

      // Simple skin color detection
      if (r > 80 && g > 50 && b > 40 && r > b && r > g) {
        skinPixels++;
      }
    }

    const skinRatio = skinPixels / (pixels.length / 4);
    return skinRatio > 0.15 ? 1 : 0; // Assume 1 face if enough skin detected
  }
}

export const autoModelManager = AutoModelManager.getInstance();
